{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a96446",
   "metadata": {},
   "source": [
    "Test notebook for basic functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e45b3fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/zac/back-testing/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: requests in /home/zac/back-testing/.venv/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: numpy in /home/zac/back-testing/.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/zac/back-testing/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install pandas requests numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dd9432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fcaa4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POCOs\n",
    "\n",
    "\n",
    "@dataclass(slots=True)\n",
    "class Candle:\n",
    "    symbol: str\n",
    "    timestamp: datetime # starting time of the candle UTC\n",
    "    open: np.float64\n",
    "    high: np.float64\n",
    "    low: np.float64\n",
    "    close: np.float64 | None = None\n",
    "    volume_base: np.float64 | None = None\n",
    "    volume_quote: np.float64 | None = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22320e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "symbols = [\"BTCUSDT\", \"ETHUSDT\"]\n",
    "candle_size = \"1m\"\n",
    "data_path = \"../data\"\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2023-06-01\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3b33fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binance_klines(symbol, interval, start_time, end_time, limit=1500):\n",
    "    \"\"\"\n",
    "    Fetch kline data from Binance futures API\n",
    "    \"\"\"\n",
    "    base_url = \"https://fapi.binance.com/fapi/v1/klines\"\n",
    "    \n",
    "    params = {\n",
    "        'symbol': symbol,\n",
    "        'interval': interval,\n",
    "        'startTime': int(start_time.timestamp() * 1000),\n",
    "        'endTime': int(end_time.timestamp() * 1000),\n",
    "        'limit': limit\n",
    "    }\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def klines_to_dataframe(klines_data):\n",
    "    \"\"\"\n",
    "    Convert Binance klines data to DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(klines_data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    \n",
    "    numeric_columns = ['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']\n",
    "    df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "    \n",
    "    df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def check_existing_data(file_path):\n",
    "    \"\"\"\n",
    "    Check what data already exists and return the latest timestamp\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        latest_timestamp = df['timestamp'].max()\n",
    "        return df, latest_timestamp\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading existing data: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6028c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing BTCUSDT...\n",
      "Found existing data with 217441 rows\n",
      "Latest timestamp: 2023-05-31 22:00:00\n",
      "Fetching data from 2023-05-31 22:01:00 to 2023-06-01 00:00:00\n",
      "Fetching 2023-05-31 22:01:00 to 2023-06-01 00:00:00\n",
      "Error fetching data for BTCUSDT: 400 Client Error: Bad Request for url: https://fapi.binance.com/fapi/v1/klines?symbol=BTCUSDT&interval=1m&startTime=1685570460000&endTime=1685570400000&limit=1500\n",
      "No new data fetched for BTCUSDT\n",
      "\n",
      "Processing ETHUSDT...\n",
      "Found existing data with 217441 rows\n",
      "Latest timestamp: 2023-05-31 22:00:00\n",
      "Fetching data from 2023-05-31 22:01:00 to 2023-06-01 00:00:00\n",
      "Fetching 2023-05-31 22:01:00 to 2023-06-01 00:00:00\n",
      "Error fetching data for ETHUSDT: 400 Client Error: Bad Request for url: https://fapi.binance.com/fapi/v1/klines?symbol=ETHUSDT&interval=1m&startTime=1685570460000&endTime=1685570400000&limit=1500\n",
      "No new data fetched for ETHUSDT\n",
      "\n",
      "Data fetching completed!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "for symbol in symbols:\n",
    "    print(f\"\\nProcessing {symbol}...\")\n",
    "    file_path = f\"{data_path}/{symbol}_{candle_size}.csv\"\n",
    "    \n",
    "    existing_df, latest_timestamp = check_existing_data(file_path)\n",
    "    \n",
    "    if existing_df is not None:\n",
    "        print(f\"Found existing data with {len(existing_df)} rows\")\n",
    "        print(f\"Latest timestamp: {latest_timestamp}\")\n",
    "        \n",
    "        fetch_start = latest_timestamp + timedelta(minutes=1)\n",
    "        if fetch_start >= end_dt:\n",
    "            print(f\"Data already up to date for {symbol}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"No existing data found for {symbol}\")\n",
    "        fetch_start = start_dt\n",
    "    \n",
    "    print(f\"Fetching data from {fetch_start} to {end_dt}\")\n",
    "    \n",
    "    all_data = []\n",
    "    current_start = fetch_start\n",
    "    \n",
    "    while current_start < end_dt:\n",
    "        current_end = min(current_start + timedelta(hours=24) - timedelta(minutes=1), end_dt)\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching {current_start} to {current_end}\")\n",
    "            klines = get_binance_klines(symbol, candle_size, current_start, current_end)\n",
    "            \n",
    "            if klines:\n",
    "                df_chunk = klines_to_dataframe(klines)\n",
    "                all_data.append(df_chunk)\n",
    "                print(f\"  Fetched {len(df_chunk)} candles\")\n",
    "                \n",
    "                if len(df_chunk) > 0:\n",
    "                    last_timestamp = df_chunk['timestamp'].max()\n",
    "                    current_start = last_timestamp + timedelta(minutes=1)\n",
    "                else:\n",
    "                    current_start = current_end + timedelta(minutes=1)\n",
    "            else:\n",
    "                current_start = current_end + timedelta(minutes=1)\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol}: {e}\")\n",
    "            break\n",
    "    \n",
    "    if all_data:\n",
    "        new_df = pd.concat(all_data, ignore_index=True)\n",
    "        new_df = new_df.drop_duplicates(subset=['timestamp']).sort_values('timestamp')\n",
    "        \n",
    "        if existing_df is not None:\n",
    "            combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "            combined_df = combined_df.drop_duplicates(subset=['timestamp']).sort_values('timestamp')\n",
    "        else:\n",
    "            combined_df = new_df\n",
    "        \n",
    "        combined_df.to_csv(file_path, index=False)\n",
    "        print(f\"Saved {len(combined_df)} total candles to {file_path}\")\n",
    "        print(f\"Date range: {combined_df['timestamp'].min()} to {combined_df['timestamp'].max()}\")\n",
    "        \n",
    "        duplicates = combined_df.duplicated(subset=['timestamp']).sum()\n",
    "        print(f\"Duplicate timestamps after deduplication: {duplicates}\")\n",
    "    else:\n",
    "        print(f\"No new data fetched for {symbol}\")\n",
    "\n",
    "print(\"\\nData fetching completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50140903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BTCUSDT:\n",
      "  Total candles: 217,441\n",
      "  Date range: 2022-12-31 22:00:00 to 2023-05-31 22:00:00\n",
      "  File size: 15,819,537 bytes\n",
      "  Sample data:\n",
      "          timestamp    open    high     low   close  volume  quote_asset_volume\n",
      "2022-12-31 22:00:00 16544.0 16544.3 16540.6 16541.0 257.084        4252826.5722\n",
      "2022-12-31 22:01:00 16540.9 16541.9 16540.9 16541.5  59.582         985566.0507\n",
      "2022-12-31 22:02:00 16541.5 16541.5 16540.5 16541.4  71.693        1185867.9968\n",
      "\n",
      "ETHUSDT:\n",
      "  Total candles: 217,441\n",
      "  Date range: 2022-12-31 22:00:00 to 2023-05-31 22:00:00\n",
      "  File size: 16,045,784 bytes\n",
      "  Sample data:\n",
      "          timestamp    open    high     low   close   volume  quote_asset_volume\n",
      "2022-12-31 22:00:00 1200.11 1200.14 1199.83 1199.84 1281.936        1.538408e+06\n",
      "2022-12-31 22:01:00 1199.84 1199.96 1199.83 1199.96  302.283        3.627078e+05\n",
      "2022-12-31 22:02:00 1199.96 1200.00 1199.95 1200.00  236.007        2.832003e+05\n"
     ]
    }
   ],
   "source": [
    "# Verify downloaded data\n",
    "for symbol in symbols:\n",
    "    file_path = f\"{data_path}/{symbol}_{candle_size}.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(f\"\\n{symbol}:\")\n",
    "        print(f\"  Total candles: {len(df):,}\")\n",
    "        print(f\"  Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "        print(f\"  File size: {os.path.getsize(file_path):,} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
